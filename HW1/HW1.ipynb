{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:11:59.866759Z","iopub.status.busy":"2025-03-24T18:11:59.866517Z","iopub.status.idle":"2025-03-24T18:12:02.740009Z","shell.execute_reply":"2025-03-24T18:12:02.738801Z","shell.execute_reply.started":"2025-03-24T18:11:59.866734Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","import csv\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import transforms, models\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# Ensure GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Kaggle dataset path and checkpoint directory\n","DATASET_PATH = \"/kaggle/input/hw1-data/data\"\n","CKPT_PATH = \"/kaggle/working/checkpoints\"\n","os.makedirs(CKPT_PATH, exist_ok=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.749441Z","iopub.status.busy":"2025-03-24T18:12:02.749092Z","iopub.status.idle":"2025-03-24T18:12:02.767453Z","shell.execute_reply":"2025-03-24T18:12:02.766497Z","shell.execute_reply.started":"2025-03-24T18:12:02.749399Z"},"trusted":true},"outputs":[],"source":["class TrainValDataset(Dataset):\n","    def __init__(self, mode='train'):\n","        super().__init__()\n","        self.mode = mode\n","        self.img_list = glob.glob(f'{DATASET_PATH}/{mode}/*/*.jpg')\n","\n","        if mode == 'train':\n","            self.preprocess = transforms.Compose([\n","                    transforms.RandomResizedCrop(224),\n","                    transforms.RandomHorizontalFlip(),\n","                    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","                    transforms.RandomRotation(10),  \n","                    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize( [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n","\n","        else:\n","            self.preprocess = transforms.Compose([\n","                    transforms.Resize(256),\n","                    transforms.CenterCrop(224),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","        \n","        print(f\"=> Loaded {len(self.img_list)} images for {mode}.\")\n","\n","    def __len__(self):\n","        return len(self.img_list)\n","    \n","    def __getitem__(self, index):\n","        img_path = self.img_list[index]\n","        img = Image.open(img_path).convert('RGB')\n","        label = int(img_path.split('/')[-2])  \n","\n","        processed_img = self.preprocess(img)\n","\n","\n","        return processed_img, torch.tensor(label, dtype=torch.long)  \n","\n","\n","class TestDataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.img_list = glob.glob(f'{DATASET_PATH}/test/*.jpg')\n","\n","        self.preprocess = transforms.Compose([\n","            transforms.Resize(256),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","        print(f\"=> Loaded {len(self.img_list)} images for testing.\")\n","\n","        # Define TTA transformations\n","        self.tta_transforms = [\n","            transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","            ]),\n","            transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.RandomHorizontalFlip(p=1.0),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","            ]),\n","            transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.RandomRotation(10),\n","                transforms.CenterCrop(224),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","            ]),\n","            transforms.Compose([\n","                transforms.Resize(256),\n","                transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","            ])\n","        ]\n","\n","    def __len__(self):\n","        return len(self.img_list)\n","    \n","    def __getitem__(self, index):\n","        img_name = os.path.basename(self.img_list[index]).split('.')[0]\n","        img = Image.open(self.img_list[index]).convert('RGB')\n","\n","        # Apply all TTA transforms\n","        tta_imgs = [transform(img) for transform in self.tta_transforms]\n","        \n","        return img_name, torch.stack(tta_imgs)  # Shape: (num_tta, C, H, W)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.769213Z","iopub.status.busy":"2025-03-24T18:12:02.768860Z","iopub.status.idle":"2025-03-24T18:12:02.793580Z","shell.execute_reply":"2025-03-24T18:12:02.792671Z","shell.execute_reply.started":"2025-03-24T18:12:02.769188Z"},"trusted":true},"outputs":[],"source":["class ResNet(nn.Module):\n","    def __init__(self, num_classes=100):\n","        super().__init__()\n","        self.resnet = models.resnet152(weights='DEFAULT')\n","        # self.resnet = torchvision.models.resnext50_32x4d(pretrained=True) \n","        # self.resnet = torchvision.models.resnext50_32x4d(weights=ResNeXt50_32X4D_Weights.DEFAULT) \n","        # self.resnet = models.resnext101_64x4d(weights='DEFAULT')\n","        # self.resnet = torchvision.models.resnext101_64x4d(weights=torchvision.models.ResNeXt101_64X4D_Weights.DEFAULT) \n","        in_features = self.resnet.fc.in_features\n","        self.resnet.fc = nn.Sequential(\n","            nn.Dropout(p=0.5), \n","            nn.Linear(in_features, num_classes)\n","        )\n","\n","    def forward(self, img):\n","        return self.resnet(img)\n","\n","def load_model(model, optimizer, save_path, device=\"cuda\"):\n","    print(f\"=> Loading checkpoint '{save_path}'...\")\n","    checkpoint = torch.load(save_path, map_location=device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch = checkpoint['epoch']\n","    print(\"=> Checkpoint Loaded.\")\n","    return model, optimizer, epoch\n","\n","def save_model(model, optimizer, epoch, save_path):\n","    print(f\"=> Saving checkpoint to '{save_path}'...\")\n","    torch.save({\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict()\n","    }, save_path)\n","    print(\"=> Checkpoint Saved.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.795312Z","iopub.status.busy":"2025-03-24T18:12:02.794905Z","iopub.status.idle":"2025-03-24T18:12:02.808399Z","shell.execute_reply":"2025-03-24T18:12:02.807514Z","shell.execute_reply.started":"2025-03-24T18:12:02.795280Z"},"trusted":true},"outputs":[],"source":["def get_model_size(model):\n","    param_num = sum(p.numel() for p in model.parameters()) / 1000000.0\n","    print(f'#Parameters: {param_num:.2f}M')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.809857Z","iopub.status.busy":"2025-03-24T18:12:02.809551Z","iopub.status.idle":"2025-03-24T18:12:02.819490Z","shell.execute_reply":"2025-03-24T18:12:02.818487Z","shell.execute_reply.started":"2025-03-24T18:12:02.809831Z"},"trusted":true},"outputs":[],"source":["def validate(model, dataloader, criterion, best_val_acc=float('-inf')):\n","    model.to(device)\n","\n","    print(\"=> Starting validation...\")\n","    model.eval()\n","\n","    total_loss, correct, total = 0.0, 0, 0\n","    with torch.no_grad():\n","        pbar = tqdm(dataloader, desc=\"Validation\")\n","\n","        for img, label in pbar:\n","            img, label = img.to(device), label.to(device)\n","            pred = model(img)\n","            loss = criterion(pred, label)\n","\n","            total_loss += loss.item()\n","            pbar.set_postfix(loss=loss.item()) \n","\n","            _, predicted = torch.max(pred, 1)\n","            correct += (predicted == label).sum().item()\n","            total += label.size(0)\n","\n","    avg_loss = total_loss / len(dataloader)\n","    acc = 100 * correct / total\n","    print(f\"Validation Avg Loss: {avg_loss}\")\n","    print(f\"Validation Avg acc: {acc}\")\n","    print(f\"best{best_val_acc} , {acc}\")\n","\n","    # Update best validation loss\n","    if acc > best_val_acc:\n","        best_val_acc = acc\n","        print(f\"âœ… New best validation acc: {best_val_acc:.6f}\")\n","\n","    return avg_loss, best_val_acc, acc\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.823133Z","iopub.status.busy":"2025-03-24T18:12:02.822840Z","iopub.status.idle":"2025-03-24T18:12:02.835617Z","shell.execute_reply":"2025-03-24T18:12:02.834575Z","shell.execute_reply.started":"2025-03-24T18:12:02.823108Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, dataloader, result_path='/kaggle/working/prediction.csv'):\n","    model.to(device)\n","    print(\"=> Starting evaluation...\")\n","    model.eval()\n","\n","    with open(result_path, 'w', newline='') as f:\n","        writer = csv.writer(f)\n","        writer.writerow(['image_name', 'pred_label'])\n","\n","        with torch.no_grad():\n","            pbar = tqdm(dataloader, desc=\"Evaluation\")\n","\n","            # for img_name, img in pbar:\n","            #     img = img.to(device)\n","            #     pred = model(img)\n","            #     writer.writerow([img_name[0], torch.argmax(pred).item()])\n","            for img_names, tta_imgs in pbar:\n","                batch_size, num_tta, C, H, W = tta_imgs.shape\n","                tta_imgs = tta_imgs.view(-1, C, H, W).to(device)  #\n","\n","                outputs = model(tta_imgs)  \n","                outputs = torch.softmax(outputs, dim=1)\n","                outputs = outputs.view(batch_size, num_tta, -1)\n","                outputs = outputs.mean(dim=1)  \n","\n","                preds = outputs.argmax(dim=1).cpu().numpy()\n","\n","                for name, pred in zip(img_names, preds):\n","                    writer.writerow([name, pred])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.837085Z","iopub.status.busy":"2025-03-24T18:12:02.836782Z","iopub.status.idle":"2025-03-24T18:12:02.851059Z","shell.execute_reply":"2025-03-24T18:12:02.850037Z","shell.execute_reply.started":"2025-03-24T18:12:02.837061Z"},"trusted":true},"outputs":[],"source":["def run_test(ckpt_root = \"/kaggle/working/checkpoints\"):\n","    \n","    mode = \"test\"\n","    ckpt_path = f\"{ckpt_root}/best_checkpoint.pth\"\n","    print(f\"âœ… Using checkpoint: {ckpt_path}\")\n","\n","    result_path = \"/kaggle/working/prediction.csv\"\n","\n","    # Load Dataset\n","    dataset = TestDataset()\n","    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n","\n","    # Initialize Model\n","    model = ResNet(num_classes=100).to(device)\n","\n","    # Load Checkpoint\n","    # optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)\n","    # optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n","    model, optimizer, _ = load_model(model, optimizer, ckpt_path, device)\n","    get_model_size(model)\n","\n","    # Evaluate Model\n","    evaluate(model, dataloader, result_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.852603Z","iopub.status.busy":"2025-03-24T18:12:02.852290Z","iopub.status.idle":"2025-03-24T18:12:02.865387Z","shell.execute_reply":"2025-03-24T18:12:02.864396Z","shell.execute_reply.started":"2025-03-24T18:12:02.852569Z"},"trusted":true},"outputs":[],"source":["def mixup_data(x, y, alpha=1.0):\n","    lam = np.random.beta(alpha, alpha)\n","    batch_size = x.size()[0]\n","    index = torch.randperm(batch_size).to(device)\n","\n","    mixed_x = lam * x + (1 - lam) * x[index, :]\n","    y_a, y_b = y, y[index]\n","    return mixed_x, y_a, y_b, lam\n","\n","def mixup_criterion(pred, y_a, y_b, lam, criterion):\n","    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:12:02.867449Z","iopub.status.busy":"2025-03-24T18:12:02.866658Z","iopub.status.idle":"2025-03-24T18:12:02.879466Z","shell.execute_reply":"2025-03-24T18:12:02.878511Z","shell.execute_reply.started":"2025-03-24T18:12:02.867412Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","def save_trainingdata():\n","\n","    df = pd.DataFrame({\n","        'epoch': list(range(start_epoch+1, start_epoch+len(train_losses) + 1)),\n","        'train_loss': train_losses,\n","        'val_loss': val_losses,\n","        'train_acc': train_accs,\n","        'val_acc': val_accs\n","    })\n","\n","    # å„²å­˜ CSV\n","    csv_path = \"/kaggle/working/training_results.csv\"\n","    df.to_csv(csv_path, index=False)\n","    print(f\"Results saved to {csv_path}\")\n","\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(start_epoch+1, start_epoch+len(train_losses) + 1), train_losses, label=\"Train Loss\", marker=\"o\")\n","    plt.plot(range(start_epoch+1, start_epoch+len(train_losses) + 1), val_losses, label=\"Validation Loss\", marker=\"s\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Training and Validation Loss\")\n","    plt.legend()\n","    plt.grid(True)\n","    \n","    plt.savefig(\"/kaggle/working/loss_plot.png\")\n","    \n","    plt.figure(figsize=(8, 6))\n","    plt.plot(range(start_epoch+1, start_epoch+len(train_losses) + 1), train_accs, label=\"Train Acc\", marker=\"o\")\n","    plt.plot(range(start_epoch+1, start_epoch+len(train_losses) + 1), val_accs, label=\"Validation Acc\", marker=\"s\")\n","    plt.xlabel(\"Epoch\")\n","    plt.ylabel(\"Acc\")\n","    plt.title(\"Training and Validation Acc\")\n","    plt.legend()\n","    plt.grid(True)\n","    \n","    plt.savefig(\"/kaggle/working/acc_plot.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-03-24T18:13:50.327020Z","iopub.status.busy":"2025-03-24T18:13:50.326634Z","iopub.status.idle":"2025-03-24T18:14:15.597080Z","shell.execute_reply":"2025-03-24T18:14:15.596112Z","shell.execute_reply.started":"2025-03-24T18:13:50.326962Z"},"trusted":true},"outputs":[],"source":["mode = \"train\"\n","ckpt_root = \"/kaggle/working/checkpoints\"\n","save_per_epoch = 1\n","batch_size = 64\n","num_epochs = 100\n","alpha_mixup = 0.2\n","patience = 20\n","resume = True \n","\n","# Load Dataset\n","dataset = TrainValDataset(mode)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataset = TrainValDataset(\"val\")\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","# Initialize Model\n","model = ResNet(num_classes=100).to(device)\n","\n","# criterion = nn.MSELoss()\n","# optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n","# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n","# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n","# scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(dataloader), epochs=num_epochs,\n","                                          # pct_start=0.1, anneal_strategy='cos', div_factor=25, final_div_factor=1e4)\n","start_epoch = 0\n","early_stop_count = 0\n","best_val_acc = float('-inf')\n","\n","if resume:\n","    ckpt_path = f'/kaggle/input/dl-hw1-model/last_checkpoint.pth'\n","    model, optimizer, start_epoch = load_model(model, optimizer, ckpt_path, device)\n","    print(f\"load_model start epoch = {start_epoch}\")\n","\n","best_epoch  = start_epoch\n","print(\"=> Starting training...\")\n","model.train()\n","\n","for epoch in range(start_epoch, num_epochs):\n","    epoch_loss, correct, total = 0.0, 0, 0\n","    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    for img, label in pbar:\n","        img, label = img.to(device), label.to(device)\n","        optimizer.zero_grad()\n","\n","        # Apply MixUp\n","        mixed_img, y_a, y_b, lam = mixup_data(img, label, alpha=alpha_mixup)\n","        pred = model(mixed_img)\n","        loss = mixup_criterion(pred, y_a, y_b, lam, criterion)\n","\n","\n","        # pred = model(img)\n","        # loss = criterion(pred, label)\n","\n","        loss.backward()\n","        optimizer.step()\n","        # scheduler.step()\n","        epoch_loss += loss.item()\n","        pbar.set_postfix(loss=loss.item())        \n","\n","        _, predicted = torch.max(pred, 1) \n","        # correct += (predicted == label).sum().item()\n","        correct += (lam * (predicted == y_a).sum().item() + (1 - lam) * (predicted == y_b).sum().item())\n","        total += label.size(0)\n","\n","\n","\n","    avg_train_acc = 100 * correct / total\n","    avg_train_loss = epoch_loss / len(dataloader)\n","    train_losses.append(avg_train_loss)\n","    train_accs.append(avg_train_acc)\n","    print(f\"Epoch {epoch+1} - Avg Train Loss: {avg_train_loss}\")\n","    print(f\"Epoch {epoch+1} - Avg Train Acc:  {avg_train_acc}\")\n","\n","\n","    # Validate after each epoch\n","    val_loss, best_val_acc, val_acc = validate(model, val_dataloader,criterion , best_val_acc)\n","    val_losses.append(val_loss)\n","    val_accs.append(val_acc)\n","\n","    scheduler.step()\n","    # scheduler.step(val_acc)\n","    # scheduler.step(val_loss)\n","    save_model(model, optimizer, epoch + 1, f'{ckpt_root}/last_checkpoint.pth')\n","\n","    # Save model if val_loss is the best\n","    if val_acc == best_val_acc:\n","        save_model(model, optimizer, epoch + 1, f'{ckpt_root}/best_checkpoint.pth')\n","        early_stop_count = 0\n","        # save_model(model, optimizer, epoch + 1, f'/kaggle/working/best_checkpoint.pth')\n","    else:\n","        early_stop_count += 1\n","    save_trainingdata()\n","\n","    ### early stop:\n","    if early_stop_count > patience:\n","        print(f\"Early stop at epoch{epoch}.\\n It is not progress from epoch {epoch - patience}.\")\n","        break\n","\n","# Automatically test with the best checkpoint\n","print(\"ðŸŽ¯ Training complete! Running test with the best checkpoint...\")\n","run_test()\n","\n","\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6861283,"sourceId":11019126,"sourceType":"datasetVersion"},{"datasetId":6866587,"sourceId":11156903,"sourceType":"datasetVersion"}],"dockerImageVersionId":30408,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
